[1m=============================================================== test session starts ================================================================
platform linux -- Python 3.9.12, pytest-6.2.2, py-1.11.0, pluggy-0.13.1 -- /home/jledesmau/miniconda3/envs/mlflow-acbfa4ee4aa9be3158264a605e4861dd8a78622b/bin/python
cachedir: .pytest_cache
rootdir: /home/jledesmau/build-model-workflow-exercises/lesson-3-data-validation/exercises/exercise_9/starter
[1mcollected 1 item                                                                                                                                   
test_data.py::test_kolmogorov_smirnov [31mFAILED
===================================================================== FAILURES =====================================================================
[31m[1m_____________________________________________________________ test_kolmogorov_smirnov ______________________________________________________________
data = (       Unnamed: 0  danceability  energy  key  ...            genre       song_name                         title     ...            O.K. - Bonus Track                     NaN                   O.K. - Bonus Track
[12593 rows x 19 columns])
ks_alpha = 0.9
    def test_kolmogorov_smirnov(data, ks_alpha):
        sample1, sample2 = data
        columns = [
            "danceability",
            "energy",
            "loudness",
            "speechiness",
            "acousticness",
            "instrumentalness",
            "liveness",
            "valence",
            "tempo",
            "duration_ms"
        ]
        # Bonferroni correction for multiple hypothesis testing
        # (see my blog post on this topic to see where this comes from:
        # https://towardsdatascience.com/precision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b)
        alpha_prime = 1 - (1 - ks_alpha)**(1 / len(columns))
        for col in columns:
            ts, p_value = scipy.stats.ks_2samp(sample1[col], sample2[col])
            # NOTE: as always, the p-value should be interpreted as the probability of
            # obtaining a test statistic (TS) equal or more extreme that the one we got
            # by chance, when the null hypothesis is true. If this probability is not
            # large enough, this dataset should be looked at carefully, hence we fail
>           assert p_value > alpha_prime
[31m[1mE           assert 0.11483872116222194 > 0.2056717652757185
[31m[1mtest_data.py[39m[22m:36: AssertionError
============================================================= short test summary info ==============================================================
FAILED test_data.py::test_kolmogorov_smirnov - assert 0.11483872116222194 > 0.2056717652757185
[31m================================================================ [1m1 failed[22m in 2.78s =================================================================